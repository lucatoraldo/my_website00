---
title: "General Social Survey (GSS)"
author: "Luca Toraldo"
date: "10/19/2020"
output: html_document
---

```{r, setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  tidy=FALSE,
  size="small")
options(digits = 3)
knitr::opts_chunk$set(
  fig.width=6.75, 
  fig.height=6.75,
  fig.align = "center")
```
```{r load-libraries, include=FALSE}
library(tidyverse)
library(mosaic)
library(ggthemes)
library(lubridate)
library(here)
library(skimr)
library(janitor)
library(httr)
library(readxl)
library(vroom)
library(infer)
library(scales)
library(tidytext)
```


The [General Social Survey (GSS)](http://www.gss.norc.org/) gathers data on American society in order to monitor and explain trends in attitudes, behaviors, and attributes. Many trends have been tracked for decades, so one can see the evolution of attitudes, etc. in American society.

Here, we analyze data from the **2016 GSS sample data**, using it to estimate values of *population parameters* of interest about US adults. The GSS sample data file has 2,867 observations of 935 variables, but we are only interested in very few of these variables.
```{r, read_gss_data, cache=TRUE}
gss <- read_csv(here::here("data", "smallgss2016.csv"), 
                na = c("", "Don't know",
                       "No answer", "Not applicable"))
```
Many responses will not be taken into consideration, like "No Answer," "Don't Know," "Not applicable," and "Refused to Answer."

We will be creating 95% confidence intervals for population parameters. The variables we have are the following:

- hours and minutes spent on email weekly. The responses to these questions are recorded in the `emailhr` and `emailmin` variables. For example, if the response is 2.50 hours, this would be recorded as emailhr = 2 and emailmin = 30.
- `snapchat`, `instagrm`, `twitter`: whether respondents used these social media in 2016
- `sex`: Female - Male
- `degree`: highest education level attained

## Instagram and Snapchat, by sex

Can we estimate the *population* proportion of Snapchat or Instagram users in 2016?

First, we will create a  new variable, `snap_insta` that is *Yes* if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and *No* if not. If the recorded value was NA for both of these questions, the value in the new variable will also be NA.
```{r, snap_insta, cache=TRUE}
gss_v2 <- gss %>% 
  na_if("NA") %>% 
  mutate(snap_insta=ifelse(snapchat == "NA" & instagrm == "NA", "NA", 
                      ifelse(snapchat == "Yes" | instagrm == "Yes", "Yes", "No")))
gss_v2
```
Second, we will calculate the proportion of Yesâ€™s for `snap_insta` among those who answered the question, excluding NAs.
```{r, proportion_snap_insta, cache=TRUE}
gss_v3 <- gss_v2 %>%
  filter(! is.na(snap_insta)) %>%
  mutate(user = ifelse(snap_insta == "Yes", 1, 0)) %>% 
  summarise(total = length(user), answer_yes = sum(user)) %>%
  mutate(prop = answer_yes / total) 
gss_v3
```
Third, using the CI formula for proportions, we will construct 95% CIs for men and women who used either Snapchat or Instagram.
```{r, CIs_snap_insta, cache=TRUE}
gss_v4 <- gss_v2 %>% 
  filter(!is.na(snap_insta)) %>%
  mutate(user = ifelse(snap_insta == "Yes", 1, 0)) %>%
  group_by(sex) %>%
  summarise(total = length(user), answer_yes = sum(user)) %>% 
  mutate(prop = answer_yes / total)
gss_v5 <- gss_v4 %>% 
  group_by(sex) %>%
  summarise(lower_95 = prop - qt(0.975, total - 1) * sqrt((prop * (1 - prop)) / total), 
            upper_95 = prop + qt(0.975, total - 1) * sqrt((prop * (1 - prop)) / total))
gss_v5
```
## Twitter, by education level

Now we will estimate the *population* proportion of Twitter users by education level in 2016. 

There are 5 education levels in variable `degree` which, in ascending order of years of education, are Lt high school, High School, Junior college, Bachelor, Graduate. 

First, we will turn `degree` from a character variable into a factor variable, making sure the order is correct and that levels are not sorted alphabetically.
```{r, factor_variable, cache=TRUE}
gss_degree <- gss %>% 
  na_if("NA") %>% 
  mutate(degree = factor(degree, levels = c("Lt high school", "High School", "Junior college", "Bachelor", "Graduate"))) %>%
  filter(!is.na(degree))
str(gss_degree$degree)
```
Next we will create a  new variable, `bachelor_graduate`, that is *Yes* if the respondent has either a `Bachelor` or `Graduate` degree. As before, if the recorded value for either was NA, the value in the new variable will also be NA.
```{r, bachelor_graduate, cache=TRUE}
bachelor_graduate <- gss_degree %>% 
  mutate(bachelor_graduate = ifelse(degree == "", "",
                      ifelse(degree == "Bachelor"|degree == "Graduate", "Yes", "No")))
bachelor_graduate
```
Then we will calculate the proportion of `bachelor_graduate` who do (Yes) and who don't (No) use Twitter. 
```{r, Yes_No_proportion, cache=TRUE}
proportion_bachelor_graduate <- bachelor_graduate %>% 
  filter(!is.na(twitter)) %>% 
  filter(bachelor_graduate == "Yes") %>% 
  group_by(twitter) %>% 
  summarise(count = n()) %>%
mutate(prop = count / sum(count))
proportion_bachelor_graduate
```
Finally, using the CI formula for proportions, we construct two 95% CIs for `bachelor_graduate` depending on whether they use (Yes) and don't (No) use Twitter. 
```{r, CI_bachelor_graduate, cache=TRUE}
CI_bachelor_graduate <- proportion_bachelor_graduate %>% 
  mutate(total = sum(count)) 
CI_bachelor_graduate %>% 
  group_by(twitter) %>%
  summarise(lower_95 = prop - qt(0.975, total - 1) * sqrt((prop * (1 - prop)) / total),
            upper_95 = prop + qt(0.975, total - 1) * sqrt((prop * (1 - prop)) / total))
```
The two confidence intervals do not overlap.

## Email usage

Can we estimate the *population* parameter on time spent on email weekly?

First, we will create a new variable called `email` that combines `emailhr` and `emailmin` to reports the number of minutes the respondents spend on email weekly.
```{r, email, cache=TRUE}
gss_email <- gss %>%
  na_if("NA") %>%
  mutate(email = as.numeric(emailhr) * 60 + as.numeric(emailmin))
gss_email
```
Next, we will visualize the distribution of this new variable.
```{r, email distribution, cache=TRUE}
gss_mean_median <- gss_email %>%
  select(email) %>% 
  filter(! is.na(email)) %>%
  summarise(mean = mean(email), median = median(email))
gss_mean_median
gss_email %>% 
  filter(! is.na(email)) %>%
ggplot(aes(x = email)) + 
  geom_density() +
  labs(subtitle = "Distribution of minutes spent on email weekly",
       title = "Snail Mail Still Rules",
       caption = "Source: General Social Survey",
       x = "Minutes spent on email weekly",
       y = "") +
  theme_bw()
```
As the variable "email" has a heavily right skew distribution, the most appropriate measure of the typical amount of time Americans spend on email is the median as it is less affected by extreme values of the considered variable.

Finally, using the `infer` package, we will calculate a 95% bootstrap confidence interval for the mean amount of time Americans spend on email weekly.
```{r, 95%_bootstrap, cache=TRUE}
gss_email_bootstrap <- gss_email %>%
  filter(! is.na(email)) %>%
  specify(response = email) %>% 
  generate(reps = 1000, type = "bootstrap") %>%
  calculate(stat = "mean")
gss_email_CI <- gss_email_bootstrap %>%
  get_ci(level = 0.95, type = "percentile")
gss_email_CI
```
Our 95% bootstrap confidence interval shows that, with 95% confidence, the true mean amount of time Americans spend on email weekly falls between the following two values: 6 hours and 27 minutes and 7 hours and 30 minutes. Taking into consideration the graphic distribution of the variable, the result seems to exaggerate the actual amount of time Americans spend checking their emails. We believe the presence of extreme values, combined with the right skew distribution of the variable, can explain the overestimation.

We would expect a 99% confidence interval to be wider because it would need to capture a greater share of the possible values. For this reason, the higher the confidence level, the wider the interval is.